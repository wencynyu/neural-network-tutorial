{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a6b184d-af11-42e9-8033-06165447f642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "操作系统及版本信息:Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.35\n",
      "系统位数:('64bit', 'ELF')\n",
      "pytorch版本:2.3.0\n",
      "cuda版本:12.1\n",
      "cudnn版本:8902\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import torch\n",
    "\n",
    "def showinfo(tip, info):\n",
    "    print(\"{}:{}\".format(tip,info))\n",
    "\n",
    "showinfo(\"操作系统及版本信息\",platform.platform())\n",
    "showinfo('系统位数', platform.architecture())\n",
    "showinfo('pytorch版本', torch.__version__)\n",
    "showinfo('cuda版本', torch.version.cuda)\n",
    "showinfo('cudnn版本', torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5874ef01-982e-43e7-abb5-255861e67136",
   "metadata": {},
   "source": [
    "## 根据理论基础note中的导数简单实现一个神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f71704-764a-4de6-b0d5-b1bba7fcfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "# 激活函数及其导数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, weight=None, bias=None, activate_func=sigmoid, activate_func_derivative=sigmoid_derivative):\n",
    "        self.weight = weight if weight is not None else random.uniform(-1, 1)\n",
    "        self.bias = bias if bias is not None else random.uniform(-1, 1)\n",
    "        self.activate_func = activate_func\n",
    "        self.activate_func_derivative = activate_func_derivative\n",
    "        self.output = None\n",
    "        self.inputs = None\n",
    "        self.delta = None\n",
    "\n",
    "    # 前向传播：激活函数（上一层输出 * 这一层weight + bias）\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = self.activate_func(sum(inputs[i] * self.weight[i] for i in range(len(inputs))) + self.bias)\n",
    "        return self.output\n",
    "\n",
    "    # 反向传播：差值 = 节点激活函数的梯度\n",
    "    def backward(self, y, learning_rate):\n",
    "        self.delta = y * self.activate_func_derivative(self.output)\n",
    "        for i in range(len(self.weight)):\n",
    "            self.weight[i] += learning_rate * self.delta * self.inputs[i]\n",
    "        self.bias += learning_rate * self.delta\n",
    "        return self.delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa7708da-c907-404f-b5d6-49fe38b59c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hidden_layer = [Node(weight=[random.uniform(-1, 1) for _ in range(input_size)]) for _ in range(hidden_size)]\n",
    "        self.output_layer = [Node(weight=[random.uniform(-1, 1) for _ in range(hidden_size)], activate_func=lambda x: x,\n",
    "                                  activate_func_derivative=lambda x: 1) for _ in range(output_size)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_outputs = [node.forward(x) for node in self.hidden_layer]\n",
    "        final_outputs = [node.forward(hidden_outputs) for node in self.output_layer]\n",
    "        return final_outputs\n",
    "\n",
    "    def backward(self, y, learning_rate):\n",
    "        output_errors = [yi - yi_pred.output for yi, yi_pred in zip(y, self.output_layer)]\n",
    "        hidden_errors = [node.backward(error, learning_rate) for node, error in zip(self.output_layer, output_errors)]\n",
    "        for node in self.hidden_layer:\n",
    "            node.backward(sum(hidden_errors), learning_rate)\n",
    "\n",
    "    def train(self, x, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            for xi, yi in zip(x, y):\n",
    "                self.forward([xi])\n",
    "                self.backward([yi], learning_rate)\n",
    "            if epoch % 1000 == 0:\n",
    "                predictions = [self.forward([xi])[0] for xi in x]\n",
    "                loss = sum((yi - yi_pred) ** 2 for yi, yi_pred in zip(y, predictions)) / len(y)\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c22b1424-62fc-42f9-bdbb-a5876dbe6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 9.910500579219743\n",
      "Epoch 1000, Loss: 0.06519984016543566\n",
      "Epoch 2000, Loss: 0.023668808720770512\n",
      "Epoch 3000, Loss: 0.012736884810698958\n",
      "Epoch 4000, Loss: 0.007905091943442164\n",
      "Epoch 5000, Loss: 0.005282467051771467\n",
      "Epoch 6000, Loss: 0.0036927461840573525\n",
      "Epoch 7000, Loss: 0.0026608095287602523\n",
      "Epoch 8000, Loss: 0.0019592242322174452\n",
      "Epoch 9000, Loss: 0.0014661825116508958\n",
      "Final predictions:\n",
      "[3.9830770013466616, 1.0412549356682734, -0.034841887954276785, 0.9810572026551035, 4.051825554052546, 8.979481589664744]\n"
     ]
    }
   ],
   "source": [
    "# 初始化数据\n",
    "x = [-2, -1, 0, 1, 2, 3]\n",
    "y = [4, 1, 0, 1, 4, 9]  # 一元二次次函数问题： y=x^2\n",
    "\n",
    "# 初始化和训练神经网络\n",
    "input_size = 1\n",
    "hidden_size = 20  # 隐藏层节点数\n",
    "output_size = 1\n",
    "epochs = 10000\n",
    "learning_rate = 0.01  # 使用较小的学习率\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "nn.train(x, y, epochs, learning_rate)\n",
    "\n",
    "# 测试训练后的神经网络\n",
    "predictions = [nn.forward([xi])[0] for xi in x]\n",
    "print(\"Final predictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef7be7-d743-4700-ba7a-0ffef7666829",
   "metadata": {},
   "source": [
    "## NN by numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a7ef7ea-1052-469c-b26e-8be6614659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, input_size, activate_func=sigmoid, activate_func_derivative=sigmoid_derivative):\n",
    "        ## numpy初始化向量\n",
    "        self.weights = np.random.uniform(-1, 1, input_size)\n",
    "        self.bias = np.random.uniform(-1, 1)\n",
    "        self.activate_func = activate_func\n",
    "        self.activate_func_derivative = activate_func_derivative\n",
    "        self.output = None\n",
    "        self.inputs = None\n",
    "        self.delta = None\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = np.array(inputs)\n",
    "        self.output = self.activate_func(np.dot(self.inputs, self.weights) + self.bias) ## 可以通过numpy的矩阵运算加速\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, y, learning_rate):\n",
    "        self.delta = y * self.activate_func_derivative(self.output)\n",
    "        self.weights += learning_rate * self.delta * self.inputs\n",
    "        self.bias += learning_rate * self.delta\n",
    "        return self.delta\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hidden_layer = [Node(input_size) for _ in range(hidden_size)]\n",
    "        self.output_layer = [Node(hidden_size, activate_func=lambda x: x, activate_func_derivative=lambda x: 1) for _ in range(output_size)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_outputs = np.array([node.forward(x) for node in self.hidden_layer])\n",
    "        final_outputs = np.array([node.forward(hidden_outputs) for node in self.output_layer])\n",
    "        return final_outputs\n",
    "\n",
    "    def backward(self, y, learning_rate):\n",
    "        output_errors = np.array([yi - yi_pred.output for yi, yi_pred in zip(y, self.output_layer)])\n",
    "        hidden_errors = np.array([node.backward(error, learning_rate) for node, error in zip(self.output_layer, output_errors)])\n",
    "        for node in self.hidden_layer:\n",
    "            node.backward(np.sum(hidden_errors), learning_rate)\n",
    "\n",
    "    def train(self, x, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            for xi, yi in zip(x, y):\n",
    "                self.forward([xi])\n",
    "                self.backward([yi], learning_rate)\n",
    "            if epoch % 1000 == 0:\n",
    "                predictions = [self.forward([xi])[0] for xi in x]\n",
    "                loss = np.mean((np.array(y) - np.array(predictions)) ** 2)\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ff33ff1-0853-476a-9686-5a88f2e3d865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 12.690397553342853\n",
      "Epoch 1000, Loss: 0.08446104376154805\n",
      "Epoch 2000, Loss: 0.034334094827737714\n",
      "Epoch 3000, Loss: 0.020305656419910563\n",
      "Epoch 4000, Loss: 0.013638394540434957\n",
      "Epoch 5000, Loss: 0.009780126692921802\n",
      "Epoch 6000, Loss: 0.007301030743069145\n",
      "Epoch 7000, Loss: 0.00560291273924175\n",
      "Epoch 8000, Loss: 0.0043889982859892105\n",
      "Epoch 9000, Loss: 0.0034940729742537874\n",
      "Final predictions:\n",
      "[3.971084067792658, 1.0710872830900582, -0.025178577447386052, 0.9359522178782205, 4.074898247479153, 8.973928099986354]\n"
     ]
    }
   ],
   "source": [
    "# 初始化数据\n",
    "x = [-2, -1, 0, 1, 2, 3]\n",
    "y = [4, 1, 0, 1, 4, 9]  # 一元二次次函数问题： y=x^2\n",
    "\n",
    "# 初始化和训练神经网络\n",
    "input_size = 1\n",
    "hidden_size = 20  # 隐藏层节点数\n",
    "output_size = 1\n",
    "epochs = 10000\n",
    "learning_rate = 0.01  # 使用较小的学习率\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "nn.train(x, y, epochs, learning_rate)\n",
    "\n",
    "# 测试训练后的神经网络\n",
    "predictions = [nn.forward([xi])[0] for xi in x]\n",
    "print(\"Final predictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adfae2d-9a57-4025-84df-f5526f5cf8e1",
   "metadata": {},
   "source": [
    "## NN by pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "958d21ca-608c-4cd4-8d7b-2c674eb8fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        ## 一个隐藏层：全连接 + sigmoid激活函数\n",
    "        self.hidden_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a6a4c6e-6ede-4376-9fde-007cd52df912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[-2.],\n",
      "        [-1.],\n",
      "        [ 0.],\n",
      "        [ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.]])\n",
      "y:  tensor([[4.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [4.],\n",
      "        [9.]])\n",
      "Epoch 0, Loss: 18.863506317138672\n",
      "Epoch 1000, Loss: 6.528347492218018\n",
      "Epoch 2000, Loss: 4.087300777435303\n",
      "Epoch 3000, Loss: 2.0222127437591553\n",
      "Epoch 4000, Loss: 0.466418594121933\n",
      "Epoch 5000, Loss: 0.07475780695676804\n",
      "Epoch 6000, Loss: 0.017330272123217583\n",
      "Epoch 7000, Loss: 0.004752637818455696\n",
      "Epoch 8000, Loss: 0.0021106048952788115\n",
      "Epoch 9000, Loss: 0.0011547842295840383\n",
      "Final predictions:\n",
      "tensor([[3.9986],\n",
      "        [0.9991],\n",
      "        [0.0300],\n",
      "        [0.9596],\n",
      "        [4.0206],\n",
      "        [8.9923]])\n"
     ]
    }
   ],
   "source": [
    "# 初始化数据\n",
    "x = [-2, -1, 0, 1, 2, 3]\n",
    "y = [4, 1, 0, 1, 4, 9]  # 一元二次次函数问题： y=x^2# 数据标准化\n",
    "\n",
    "# 转换为Tensor\n",
    "x = torch.tensor(x, dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "print('x: ', x)\n",
    "print('y: ', y)\n",
    "\n",
    "# 初始化和训练神经网络\n",
    "input_size = 1\n",
    "hidden_size = 10\n",
    "output_size = 1\n",
    "epochs = 10000\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "# 使用均方误差作为损失函数，最速梯度下降作为优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# 测试训练后的神经网络\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(x)\n",
    "    print(\"Final predictions:\")\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd125a-83eb-47d2-969a-44071872a8b3",
   "metadata": {},
   "source": [
    "## 补充：n元n次方程模拟，二元一次为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3420b2ce-1c21-47fc-95d2-dc49930c35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class NormalNN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dimension, out_dimension):\n",
    "        super(NormalNN, self).__init__()\n",
    "\n",
    "        self.hide_layer_func = nn.Linear(in_dimension, 10)\n",
    "        self.out_layer_func = nn.Linear(10, out_dimension)\n",
    "        self.activate_func = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hide_layer_func(x)\n",
    "        x = self.activate_func(x)\n",
    "        x = self.out_layer_func(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "494a9577-0c8b-4f81-a42c-802658089f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Loss: 0.0365\n",
      "Epoch [20/500], Loss: 0.0323\n",
      "Epoch [30/500], Loss: 0.0285\n",
      "Epoch [40/500], Loss: 0.0251\n",
      "Epoch [50/500], Loss: 0.0221\n",
      "Epoch [60/500], Loss: 0.0194\n",
      "Epoch [70/500], Loss: 0.0171\n",
      "Epoch [80/500], Loss: 0.0150\n",
      "Epoch [90/500], Loss: 0.0131\n",
      "Epoch [100/500], Loss: 0.0115\n",
      "Epoch [110/500], Loss: 0.0100\n",
      "Epoch [120/500], Loss: 0.0088\n",
      "Epoch [130/500], Loss: 0.0076\n",
      "Epoch [140/500], Loss: 0.0066\n",
      "Epoch [150/500], Loss: 0.0058\n",
      "Epoch [160/500], Loss: 0.0050\n",
      "Epoch [170/500], Loss: 0.0044\n",
      "Epoch [180/500], Loss: 0.0038\n",
      "Epoch [190/500], Loss: 0.0033\n",
      "Epoch [200/500], Loss: 0.0028\n",
      "Epoch [210/500], Loss: 0.0025\n",
      "Epoch [220/500], Loss: 0.0021\n",
      "Epoch [230/500], Loss: 0.0018\n",
      "Epoch [240/500], Loss: 0.0016\n",
      "Epoch [250/500], Loss: 0.0014\n",
      "Epoch [260/500], Loss: 0.0012\n",
      "Epoch [270/500], Loss: 0.0010\n",
      "Epoch [280/500], Loss: 0.0009\n",
      "Epoch [290/500], Loss: 0.0008\n",
      "Epoch [300/500], Loss: 0.0006\n",
      "Epoch [310/500], Loss: 0.0006\n",
      "Epoch [320/500], Loss: 0.0005\n",
      "Epoch [330/500], Loss: 0.0004\n",
      "Epoch [340/500], Loss: 0.0004\n",
      "Epoch [350/500], Loss: 0.0003\n",
      "Epoch [360/500], Loss: 0.0003\n",
      "Epoch [370/500], Loss: 0.0002\n",
      "Epoch [380/500], Loss: 0.0002\n",
      "Epoch [390/500], Loss: 0.0002\n",
      "Epoch [400/500], Loss: 0.0001\n",
      "Epoch [410/500], Loss: 0.0001\n",
      "Epoch [420/500], Loss: 0.0001\n",
      "Epoch [430/500], Loss: 0.0001\n",
      "Epoch [440/500], Loss: 0.0001\n",
      "Epoch [450/500], Loss: 0.0001\n",
      "Epoch [460/500], Loss: 0.0001\n",
      "Epoch [470/500], Loss: 0.0000\n",
      "Epoch [480/500], Loss: 0.0000\n",
      "Epoch [490/500], Loss: 0.0000\n",
      "Epoch [500/500], Loss: 0.0000\n",
      "Prediction: [8.99134349822998, 12.810791015625]\n"
     ]
    }
   ],
   "source": [
    "# 创建模型实例\n",
    "model = NormalNN(2, 1)\n",
    "\n",
    "# 使用均方误差作为损失函数，最速梯度下降作为优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # 学习率为0.01\n",
    "\n",
    "# 输入数据\n",
    "inputs = torch.tensor([[1.0, 2.0], [2.0, 3.0], [3.0, 4.0]])\n",
    "outputs = torch.tensor([[3.0], [5.0], [7.0]])\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    # 前向传播\n",
    "    predictions = model(inputs)\n",
    "    # 计算损失\n",
    "    loss = criterion(predictions, outputs)\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 测试模型\n",
    "test_input = torch.tensor([[4.0, 5.0], [3.14, 9.29]])\n",
    "with torch.no_grad():\n",
    "    prediction = model(test_input)\n",
    "    print(\"Prediction:\", prediction.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead33df-67ad-42c5-940f-cd7fa17bdcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021d2e91-5feb-40e6-814c-b33449254bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
